1.缺失的age可以由name中的Mr、Mrs来决定（平均值）

但是好像：
12岁以下的男孩叫master，12岁以上的男孩叫mr 
没结婚的女孩都叫miss（大概30岁以下）， 结婚了之后叫mrs


2.data correcting ：
处理aberrant value（目前还不知道如何识别离群点，应该是画图吧，没试过）————用箱线图可以很直观看出

3.data completing：
qualitative data：用众数
quantitative data：用means、median 或者means+随机标准数
或者也可以向我之前一样（根据pclass来对Fare做缺失值填充）

（当然，麻烦点的话，可以做一个很简单的随机森林，对缺失值进行预测）（比如预测乘客的age）


4.数据清洗在特征工程之前，用于修正aberrant值，impute missing value
    而特征工程包括：从现有特征中创造新特征（如家庭人数）， 将特征的format做个转换（比如onehot， labelencode， log化， 标准化， 归一化）， 特征的筛选
	tips：①  特征的筛选时，也可以创建多个筛选列表，在后期训练模型时候也可以做个比较，什么样的特征选取，得到的模型更好一些。[name, age], [fare, pclass, cabin, age]
			  而且也可以让各个特征对target label作个相关性系数的图表（能够比较清晰的看出相关性，排除关系较小的特征（可能是干扰特征））
			
		  ②  新特征的创造：1.多个特征拼接合并   2.单个特征拆分  eg。把兄弟姐妹合并成家庭， 把名字或性别拆分成mr、mrs、miss等等（更细分）
			因为有时候单靠一个性别很难做更好的训练和预测。比如男性的生存率很低，但是小孩的生存率很高，那么小男孩的生存率如何呢？很难说吧。那就需要多性别进行”再分割“， 这样才能让模型有更多学习的空间，才能让模型拟合的更好。（我titanic的模型的train的score也不高，说明欠拟合了，可能这是一个原因）
			（怎么调，在train集都是欠拟合的话，说明特征选择不恰当，或者数据本身不符合数理特性）
			（似乎决策树类算法容易过拟合，其他算法容易欠拟合，与算法本身有关。。。）
			（而且feature depends on the model！！可能特征A在tree里很重要，但是在svm里就很不重要）

tips：
1.不用那么着急把数据切分成features和labels， 之后split的时候用一个变量索引去取值就好了
（而且这么多变量名叠加看得头大）
2.最开始的时候也不用合并test集和train集。用[train， test]的形式， 后面用for循环去同时操作就好了
3.其实可以写一个函数：就是完整的数据清洗、转换format的流程（这样任何原始数据，传进来，都直接被清洗好了，可以直接进行预测了）
   这样也可以省去train_data、test_data合并、拆分的过程。。。。。（下次试试看）

4.过拟合和欠拟合，我可能会选择稍微过一点。（指的是自测的score）
   最好选择train数据和test数据的score都差不多的模型，这样显得不会太过拟合。
   split最好不要选0.1:0.9， 这样得到的test集的score虽然会高，但是也有可能是你对train数据没训练好，还是欠着的，但是由于test集数量特别少，很容易让垃圾模型恰好对少数据量的test集得到很好的分数，造成过拟合的最终成果。（这就是为什么train的score低，而test的score高的缘故了）
   以后尝试以下0.5:0.5的， 这样训练出来的模型应该泛化能力比较强，这样验证集的score应该能比较好的体现最终submit的score了吧？
   
   不要太指望自己train/test的score在0.1以下， 有时候那么低了就已经是过拟合了。（据经验，0.4-0.6之间都还算正常的）
   
5.如果把某个脚本作为example，一定要把这个脚本写成函数的形式！！！！！！！！！！！！
否则在代码重用时候，即使是改个变量名，都要耗费大量的时间！！！！！
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   
   