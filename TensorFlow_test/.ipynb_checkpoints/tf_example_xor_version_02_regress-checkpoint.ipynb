{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import math\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义一个类， 用于取数据(提供next_batch借口,分批次提取数据)\n",
    "# （不正规，以后应该都要用TFrecord的）\n",
    "class xy_iterator():\n",
    "    def __init__(self, x, y):\n",
    "        self.original_x = x\n",
    "        self.original_y = y\n",
    "        self.x = iter(self.original_x)\n",
    "        self.y = iter(self.original_y)\n",
    "    \n",
    "    def next_batch(self,batch_size):\n",
    "        self.x_list = []\n",
    "        self.y_list = []\n",
    "        try:\n",
    "            for _ in range(batch_size):\n",
    "                self.x_list.append(next(self.x))\n",
    "                self.y_list.append(next(self.y))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        return (self.x_list, self.y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一。 数据处理、准备阶段\n",
    "train_features = [\n",
    "    [1, 1],\n",
    "    [0, 0],\n",
    "    [1, 0],\n",
    "    [0, 1]\n",
    "]\n",
    "train_labels = [\n",
    "    [0],\n",
    "    [0],\n",
    "    [1],\n",
    "    [1]\n",
    "]\n",
    "train_data_num = 4\n",
    "xy_iter = xy_iterator(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 二。 超参数、placeholder、w、b的设定\n",
    "input_features_num = 2\n",
    "hidden_layer_1_num = 40\n",
    "output_classes= 1\n",
    "\n",
    "\n",
    "x = tf.placeholder(\"float\", [None,2], \"x\")\n",
    "y = tf.placeholder(\"float\", [None,1], \"y\")\n",
    "\n",
    "\n",
    "weights = {\n",
    "    \"w1\" : tf.Variable(tf.random_normal([input_features_num, hidden_layer_1_num]), \"w1\"),\n",
    "    \"w2\" : tf.Variable(tf.random_normal([hidden_layer_1_num, output_classes]), \"w2\")\n",
    "}\n",
    "biases = {\n",
    "    \"b1\" : tf.Variable(tf.random_normal([hidden_layer_1_num]), \"b1\"),\n",
    "    \"b2\" : tf.Variable(tf.random_normal([output_classes]), \"b2\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 三、 定义模型（网络结构）\n",
    "def mlp(x, weights, biases):\n",
    "    layer_1 = tf.matmul(x, weights[\"w1\"])\n",
    "#     layer_1 = tf.add(layer_1, biases[\"b1\"])\n",
    "    layer_1 = tf.nn.relu(layer_1, name=\"relu\")\n",
    "    output = tf.matmul(layer_1, weights[\"w2\"])\n",
    "#     output = tf.add(output, biases[\"b2\"])\n",
    "    return output\n",
    "pred_model = mlp(x, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 四、 定义（loss + optimizer + metric）\n",
    "loss_all = tf.square(pred_model - y)\n",
    "loss = tf.reduce_mean(loss_all) + tf.contrib.layers.l2_regularizer(0.05)(weights[\"w1\"])\n",
    "# loss = tf.reduce_mean(loss_all)\n",
    "# learning_rate = 0.01\n",
    "global_step = tf.Variable(0)\n",
    "learning_rate = tf.train.exponential_decay(0.1, global_step, 50, 0.95)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss, global_step=global_step)\n",
    "# TD: metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.0 epoch: average loss = 4.6522\n",
      "No.1 epoch: average loss = 5.8924\n",
      "No.2 epoch: average loss = 2.5854\n",
      "No.3 epoch: average loss = 3.0589\n",
      "No.4 epoch: average loss = 1.2848\n",
      "No.5 epoch: average loss = 0.9481\n",
      "No.6 epoch: average loss = 1.2359\n",
      "No.7 epoch: average loss = 0.9659\n",
      "No.8 epoch: average loss = 0.9065\n",
      "No.9 epoch: average loss = 0.7224\n",
      "No.10 epoch: average loss = 0.7132\n",
      "No.11 epoch: average loss = 0.7497\n",
      "No.12 epoch: average loss = 0.6436\n",
      "No.13 epoch: average loss = 0.6720\n",
      "No.14 epoch: average loss = 0.6005\n",
      "No.15 epoch: average loss = 0.5797\n",
      "No.16 epoch: average loss = 0.5959\n",
      "No.17 epoch: average loss = 0.5431\n",
      "No.18 epoch: average loss = 0.5160\n",
      "No.19 epoch: average loss = 0.4975\n",
      "No.20 epoch: average loss = 0.4744\n",
      "No.21 epoch: average loss = 0.4619\n",
      "No.22 epoch: average loss = 0.4359\n",
      "No.23 epoch: average loss = 0.4169\n",
      "No.24 epoch: average loss = 0.4051\n",
      "No.25 epoch: average loss = 0.3840\n",
      "No.26 epoch: average loss = 0.3688\n",
      "No.27 epoch: average loss = 0.3548\n",
      "No.28 epoch: average loss = 0.3385\n",
      "No.29 epoch: average loss = 0.3256\n",
      "No.30 epoch: average loss = 0.3108\n",
      "No.31 epoch: average loss = 0.2983\n",
      "No.32 epoch: average loss = 0.2880\n",
      "No.33 epoch: average loss = 0.2757\n",
      "No.34 epoch: average loss = 0.2649\n",
      "No.35 epoch: average loss = 0.2540\n",
      "No.36 epoch: average loss = 0.2452\n",
      "No.37 epoch: average loss = 0.2357\n",
      "No.38 epoch: average loss = 0.2264\n",
      "No.39 epoch: average loss = 0.2175\n",
      "No.40 epoch: average loss = 0.2092\n",
      "No.41 epoch: average loss = 0.2022\n",
      "No.42 epoch: average loss = 0.1945\n",
      "No.43 epoch: average loss = 0.1871\n",
      "No.44 epoch: average loss = 0.1803\n",
      "No.45 epoch: average loss = 0.1741\n",
      "No.46 epoch: average loss = 0.1677\n",
      "No.47 epoch: average loss = 0.1614\n",
      "No.48 epoch: average loss = 0.1557\n",
      "No.49 epoch: average loss = 0.1503\n",
      "No.50 epoch: average loss = 0.1448\n",
      "No.51 epoch: average loss = 0.1395\n",
      "No.52 epoch: average loss = 0.1346\n",
      "No.53 epoch: average loss = 0.1304\n",
      "No.54 epoch: average loss = 0.1256\n",
      "No.55 epoch: average loss = 0.1212\n",
      "No.56 epoch: average loss = 0.1170\n",
      "No.57 epoch: average loss = 0.1130\n",
      "No.58 epoch: average loss = 0.1089\n",
      "No.59 epoch: average loss = 0.1053\n",
      "No.60 epoch: average loss = 0.1020\n",
      "No.61 epoch: average loss = 0.0985\n",
      "No.62 epoch: average loss = 0.0950\n",
      "No.63 epoch: average loss = 0.0918\n",
      "No.64 epoch: average loss = 0.0893\n",
      "No.65 epoch: average loss = 0.0859\n",
      "No.66 epoch: average loss = 0.0830\n",
      "No.67 epoch: average loss = 0.0811\n",
      "No.68 epoch: average loss = 0.0781\n",
      "No.69 epoch: average loss = 0.0750\n",
      "No.70 epoch: average loss = 0.0733\n",
      "No.71 epoch: average loss = 0.0708\n",
      "No.72 epoch: average loss = 0.0684\n",
      "No.73 epoch: average loss = 0.0661\n",
      "No.74 epoch: average loss = 0.0650\n",
      "No.75 epoch: average loss = 0.0625\n",
      "No.76 epoch: average loss = 0.0600\n",
      "No.77 epoch: average loss = 0.0589\n",
      "No.78 epoch: average loss = 0.0571\n",
      "No.79 epoch: average loss = 0.0550\n",
      "No.80 epoch: average loss = 0.0532\n",
      "No.81 epoch: average loss = 0.0515\n",
      "No.82 epoch: average loss = 0.0500\n",
      "No.83 epoch: average loss = 0.0483\n",
      "No.84 epoch: average loss = 0.0475\n",
      "No.85 epoch: average loss = 0.0457\n",
      "No.86 epoch: average loss = 0.0444\n",
      "No.87 epoch: average loss = 0.0436\n",
      "No.88 epoch: average loss = 0.0422\n",
      "No.89 epoch: average loss = 0.0408\n",
      "No.90 epoch: average loss = 0.0405\n",
      "No.91 epoch: average loss = 0.0389\n",
      "No.92 epoch: average loss = 0.0377\n",
      "No.93 epoch: average loss = 0.0381\n",
      "No.94 epoch: average loss = 0.0362\n",
      "No.95 epoch: average loss = 0.0362\n",
      "No.96 epoch: average loss = 0.0348\n",
      "No.97 epoch: average loss = 0.0333\n",
      "No.98 epoch: average loss = 0.0327\n",
      "No.99 epoch: average loss = 0.0317\n",
      "No.100 epoch: average loss = 0.0313\n",
      "No.101 epoch: average loss = 0.0297\n",
      "No.102 epoch: average loss = 0.0296\n",
      "No.103 epoch: average loss = 0.0286\n",
      "No.104 epoch: average loss = 0.0276\n",
      "No.105 epoch: average loss = 0.0277\n",
      "No.106 epoch: average loss = 0.0267\n",
      "No.107 epoch: average loss = 0.0260\n",
      "No.108 epoch: average loss = 0.0254\n",
      "No.109 epoch: average loss = 0.0247\n",
      "No.110 epoch: average loss = 0.0252\n",
      "No.111 epoch: average loss = 0.0235\n",
      "No.112 epoch: average loss = 0.0234\n",
      "No.113 epoch: average loss = 0.0229\n",
      "No.114 epoch: average loss = 0.0230\n",
      "No.115 epoch: average loss = 0.0220\n",
      "No.116 epoch: average loss = 0.0214\n",
      "No.117 epoch: average loss = 0.0207\n",
      "No.118 epoch: average loss = 0.0204\n",
      "No.119 epoch: average loss = 0.0201\n",
      "No.120 epoch: average loss = 0.0193\n",
      "No.121 epoch: average loss = 0.0193\n",
      "No.122 epoch: average loss = 0.0186\n",
      "No.123 epoch: average loss = 0.0204\n",
      "No.124 epoch: average loss = 0.0184\n",
      "No.125 epoch: average loss = 0.0212\n",
      "No.126 epoch: average loss = 0.0199\n",
      "No.127 epoch: average loss = 0.0201\n",
      "No.128 epoch: average loss = 0.0184\n",
      "No.129 epoch: average loss = 0.0180\n",
      "No.130 epoch: average loss = 0.0197\n",
      "No.131 epoch: average loss = 0.0174\n",
      "No.132 epoch: average loss = 0.0240\n",
      "No.133 epoch: average loss = 0.0263\n",
      "No.134 epoch: average loss = 0.0344\n",
      "No.135 epoch: average loss = 0.0281\n",
      "No.136 epoch: average loss = 0.0237\n",
      "No.137 epoch: average loss = 0.0222\n",
      "No.138 epoch: average loss = 0.0241\n",
      "No.139 epoch: average loss = 0.0210\n",
      "No.140 epoch: average loss = 0.0195\n",
      "No.141 epoch: average loss = 0.0195\n",
      "No.142 epoch: average loss = 0.0177\n",
      "No.143 epoch: average loss = 0.0311\n",
      "No.144 epoch: average loss = 0.0338\n",
      "No.145 epoch: average loss = 0.0274\n",
      "No.146 epoch: average loss = 0.0275\n",
      "No.147 epoch: average loss = 0.0353\n",
      "No.148 epoch: average loss = 0.0260\n",
      "No.149 epoch: average loss = 0.0263\n",
      "No.150 epoch: average loss = 0.0224\n",
      "No.151 epoch: average loss = 0.0241\n",
      "No.152 epoch: average loss = 0.0189\n",
      "No.153 epoch: average loss = 0.0198\n",
      "No.154 epoch: average loss = 0.0170\n",
      "No.155 epoch: average loss = 0.0189\n",
      "No.156 epoch: average loss = 0.0144\n",
      "No.157 epoch: average loss = 0.0148\n",
      "No.158 epoch: average loss = 0.0143\n",
      "No.159 epoch: average loss = 0.0135\n",
      "No.160 epoch: average loss = 0.0130\n",
      "No.161 epoch: average loss = 0.0143\n",
      "No.162 epoch: average loss = 0.0130\n",
      "No.163 epoch: average loss = 0.0155\n",
      "No.164 epoch: average loss = 0.0134\n",
      "No.165 epoch: average loss = 0.0132\n",
      "No.166 epoch: average loss = 0.0134\n",
      "No.167 epoch: average loss = 0.0132\n",
      "No.168 epoch: average loss = 0.0120\n",
      "No.169 epoch: average loss = 0.0155\n",
      "No.170 epoch: average loss = 0.0144\n",
      "No.171 epoch: average loss = 0.0131\n",
      "No.172 epoch: average loss = 0.0146\n",
      "No.173 epoch: average loss = 0.0137\n",
      "No.174 epoch: average loss = 0.0126\n",
      "No.175 epoch: average loss = 0.0124\n",
      "No.176 epoch: average loss = 0.0116\n",
      "No.177 epoch: average loss = 0.0111\n",
      "No.178 epoch: average loss = 0.0178\n",
      "No.179 epoch: average loss = 0.0152\n",
      "No.180 epoch: average loss = 0.0148\n",
      "No.181 epoch: average loss = 0.0171\n",
      "No.182 epoch: average loss = 0.0160\n",
      "No.183 epoch: average loss = 0.0148\n",
      "No.184 epoch: average loss = 0.0142\n",
      "No.185 epoch: average loss = 0.0153\n",
      "No.186 epoch: average loss = 0.0121\n",
      "No.187 epoch: average loss = 0.0135\n",
      "No.188 epoch: average loss = 0.0153\n",
      "No.189 epoch: average loss = 0.0135\n",
      "No.190 epoch: average loss = 0.0141\n",
      "No.191 epoch: average loss = 0.0107\n",
      "No.192 epoch: average loss = 0.0117\n",
      "No.193 epoch: average loss = 0.0095\n",
      "No.194 epoch: average loss = 0.0174\n",
      "No.195 epoch: average loss = 0.0159\n",
      "No.196 epoch: average loss = 0.0128\n",
      "No.197 epoch: average loss = 0.0186\n",
      "No.198 epoch: average loss = 0.0156\n",
      "No.199 epoch: average loss = 0.0161\n",
      "No.200 epoch: average loss = 0.0151\n",
      "No.201 epoch: average loss = 0.0150\n",
      "No.202 epoch: average loss = 0.0137\n",
      "No.203 epoch: average loss = 0.0132\n",
      "No.204 epoch: average loss = 0.0114\n",
      "No.205 epoch: average loss = 0.0113\n",
      "No.206 epoch: average loss = 0.0100\n",
      "No.207 epoch: average loss = 0.0098\n",
      "No.208 epoch: average loss = 0.0111\n",
      "No.209 epoch: average loss = 0.0106\n",
      "No.210 epoch: average loss = 0.0188\n",
      "No.211 epoch: average loss = 0.0227\n",
      "No.212 epoch: average loss = 0.0365\n",
      "No.213 epoch: average loss = 0.0239\n",
      "No.214 epoch: average loss = 0.0169\n",
      "No.215 epoch: average loss = 0.0251\n",
      "No.216 epoch: average loss = 0.0301\n",
      "No.217 epoch: average loss = 0.0215\n",
      "No.218 epoch: average loss = 0.0226\n",
      "No.219 epoch: average loss = 0.0179\n",
      "No.220 epoch: average loss = 0.0198\n",
      "No.221 epoch: average loss = 0.0176\n",
      "No.222 epoch: average loss = 0.0151\n",
      "No.223 epoch: average loss = 0.0219\n",
      "No.224 epoch: average loss = 0.0164\n",
      "No.225 epoch: average loss = 0.0165\n",
      "No.226 epoch: average loss = 0.0146\n",
      "No.227 epoch: average loss = 0.0155\n",
      "No.228 epoch: average loss = 0.0136\n",
      "No.229 epoch: average loss = 0.0139\n",
      "No.230 epoch: average loss = 0.0117\n",
      "No.231 epoch: average loss = 0.0115\n",
      "No.232 epoch: average loss = 0.0100\n",
      "No.233 epoch: average loss = 0.0095\n",
      "No.234 epoch: average loss = 0.0085\n",
      "No.235 epoch: average loss = 0.0087\n",
      "No.236 epoch: average loss = 0.0075\n",
      "No.237 epoch: average loss = 0.0102\n",
      "No.238 epoch: average loss = 0.0152\n",
      "No.239 epoch: average loss = 0.0549\n",
      "No.240 epoch: average loss = 0.0498\n",
      "No.241 epoch: average loss = 0.0429\n",
      "No.242 epoch: average loss = 0.0322\n",
      "No.243 epoch: average loss = 0.0424\n",
      "No.244 epoch: average loss = 0.0363\n",
      "No.245 epoch: average loss = 0.0294\n",
      "No.246 epoch: average loss = 0.0350\n",
      "No.247 epoch: average loss = 0.0257\n",
      "No.248 epoch: average loss = 0.0294\n",
      "No.249 epoch: average loss = 0.0233\n",
      "No.250 epoch: average loss = 0.0250\n",
      "No.251 epoch: average loss = 0.0219\n",
      "No.252 epoch: average loss = 0.0202\n",
      "No.253 epoch: average loss = 0.0179\n",
      "No.254 epoch: average loss = 0.0177\n",
      "No.255 epoch: average loss = 0.0152\n",
      "No.256 epoch: average loss = 0.0143\n",
      "No.257 epoch: average loss = 0.0133\n",
      "No.258 epoch: average loss = 0.0123\n",
      "No.259 epoch: average loss = 0.0114\n",
      "No.260 epoch: average loss = 0.0104\n",
      "No.261 epoch: average loss = 0.0097\n",
      "No.262 epoch: average loss = 0.0095\n",
      "No.263 epoch: average loss = 0.0088\n",
      "No.264 epoch: average loss = 0.0133\n",
      "No.265 epoch: average loss = 0.0166\n",
      "No.266 epoch: average loss = 0.0099\n",
      "No.267 epoch: average loss = 0.0128\n",
      "No.268 epoch: average loss = 0.0113\n",
      "No.269 epoch: average loss = 0.0105\n",
      "No.270 epoch: average loss = 0.0103\n",
      "No.271 epoch: average loss = 0.0099\n",
      "No.272 epoch: average loss = 0.0101\n",
      "No.273 epoch: average loss = 0.0091\n",
      "No.274 epoch: average loss = 0.0087\n",
      "No.275 epoch: average loss = 0.0086\n",
      "No.276 epoch: average loss = 0.0077\n",
      "No.277 epoch: average loss = 0.0075\n",
      "No.278 epoch: average loss = 0.0074\n",
      "No.279 epoch: average loss = 0.0071\n",
      "No.280 epoch: average loss = 0.0064\n",
      "No.281 epoch: average loss = 0.0064\n",
      "No.282 epoch: average loss = 0.0062\n",
      "No.283 epoch: average loss = 0.0061\n",
      "No.284 epoch: average loss = 0.0058\n",
      "No.285 epoch: average loss = 0.0059\n",
      "No.286 epoch: average loss = 0.0057\n",
      "No.287 epoch: average loss = 0.0061\n",
      "No.288 epoch: average loss = 0.0058\n",
      "No.289 epoch: average loss = 0.0059\n",
      "No.290 epoch: average loss = 0.0059\n",
      "No.291 epoch: average loss = 0.0057\n",
      "No.292 epoch: average loss = 0.0058\n",
      "No.293 epoch: average loss = 0.0056\n",
      "No.294 epoch: average loss = 0.0056\n",
      "No.295 epoch: average loss = 0.0054\n",
      "No.296 epoch: average loss = 0.0054\n",
      "No.297 epoch: average loss = 0.0053\n",
      "No.298 epoch: average loss = 0.0054\n",
      "No.299 epoch: average loss = 0.0053\n"
     ]
    }
   ],
   "source": [
    "#  五、 执行训练模型\n",
    "training_epochs = 300\n",
    "batch_size = 2\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(training_epochs):\n",
    "        total_batch_num = math.ceil(train_data_num/batch_size)\n",
    "        total_loss = 0\n",
    "        xy_iter = xy_iterator(train_features, train_labels)\n",
    "        for _ in range(total_batch_num):\n",
    "            xs, ys = xy_iter.next_batch(batch_size)\n",
    "            l, _ = sess.run([loss, optimizer], feed_dict={x:xs, y:ys})\n",
    "            total_loss += l\n",
    "        print(\"No.{0} epoch: average loss = {1:.4f}\".format(i, total_loss/total_batch_num))\n",
    "    \n",
    "    # 六、 预测 + 评估     \n",
    "    w,b = sess.run([weights, biases])\n",
    "    pred_y = sess.run(pred_model, feed_dict={x:[[1,1], [0, 1], [1, 0], [0, 0]]}) # 此处得到的便是模型的预测值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00915546],\n",
       "       [0.996091  ],\n",
       "       [1.0013257 ],\n",
       "       [0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-5.3328224e-03 -1.4355890e-06 -9.1333658e-04 -8.3457865e-03\n",
      "   1.6095737e-01 -2.9884330e-03 -1.9439808e-04 -2.1041473e-03\n",
      "  -5.7716860e-04  1.8087260e-02  5.7424377e-03 -3.4281951e-03\n",
      "  -9.4640583e-02  2.7607835e-03 -1.1615967e-03 -4.8087679e-02\n",
      "  -4.9618820e-10 -7.3198549e-02  3.1899360e-03  3.8144456e-03\n",
      "  -3.2875556e-03 -4.3448233e-03  5.0177619e-08 -8.1546856e-03\n",
      "  -1.1717254e-02 -6.4305542e-03  6.4909208e-04  1.5787663e-02\n",
      "  -1.1148748e-03  2.1444963e-02 -1.9658080e-01 -1.3615978e-03\n",
      "   1.1052746e-01  2.0098144e-03  6.1821779e-03 -7.9682260e-04\n",
      "   9.4263844e-02 -3.9622560e-04  3.0180430e-03  5.6379408e-02]\n",
      " [-1.6477733e-03 -1.1031595e-06 -3.5220355e-04 -9.1667171e-05\n",
      "  -1.4979161e-01 -1.1855995e-02 -7.0644572e-05 -8.7847683e-04\n",
      "   5.6470704e-04  8.2726550e-04  1.3143229e-02 -2.8051629e-03\n",
      "   9.4670080e-02  4.8062382e-03  1.4727578e-03  5.2015990e-02\n",
      "  -1.7596134e-06  7.3832020e-02  5.9906457e-04  2.0985113e-04\n",
      "  -2.7212217e-03 -5.6135608e-03 -1.5688556e-05 -8.4136249e-03\n",
      "  -6.3521764e-04 -4.4850553e-03  4.3963319e-05 -1.6578646e-02\n",
      "  -3.0458428e-05 -2.6353506e-02  1.9085038e-01 -8.7311497e-04\n",
      "  -1.1754234e-01  2.0370167e-03  9.3591347e-04 -3.3898742e-04\n",
      "  -9.6279606e-02  5.5297598e-04  7.4815383e-04 -5.7842590e-02]]\n",
      "[[False  True False False False False False False False False False False\n",
      "  False False False False  True False False False False False  True False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False]\n",
      " [False  True False  True False False  True False False False False False\n",
      "  False False False False  True False False False False False  True False\n",
      "  False False  True False  True False False False False False False False\n",
      "  False False False False]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.abs(w[\"w1\"]) < 0.0001\n",
    "print(w[\"w1\"])\n",
    "print(a)\n",
    "a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
