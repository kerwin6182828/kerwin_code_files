{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import math\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义一个类， 用于取数据(提供next_batch借口,分批次提取数据)\n",
    "# （不正规，以后应该都要用TFrecord的）\n",
    "class xy_iterator():\n",
    "    def __init__(self, x, y):\n",
    "        self.original_x = x\n",
    "        self.original_y = y\n",
    "        self.x = iter(self.original_x)\n",
    "        self.y = iter(self.original_y)\n",
    "    \n",
    "    def next_batch(self,batch_size):\n",
    "        self.x_list = []\n",
    "        self.y_list = []\n",
    "        try:\n",
    "            for _ in range(batch_size):\n",
    "                self.x_list.append(next(self.x))\n",
    "                self.y_list.append(next(self.y))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        return (self.x_list, self.y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一。 数据处理、准备阶段\n",
    "train_features = [\n",
    "    [1, 1],\n",
    "    [0, 0],\n",
    "    [1, 0],\n",
    "    [0, 1]\n",
    "]\n",
    "train_labels = [\n",
    "    [1, 0],\n",
    "    [1, 0],\n",
    "    [0, 1],\n",
    "    [0, 1]\n",
    "]\n",
    "train_data_num = 4\n",
    "xy_iter = xy_iterator(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 二。 超参数、placeholder、w、b的设定\n",
    "input_features_num = 2\n",
    "hidden_layer_1_num = 400\n",
    "output_classes= 2\n",
    "\n",
    "\n",
    "x = tf.placeholder(\"float\", [None,2], \"x\")\n",
    "y = tf.placeholder(\"float\", [None,2], \"y\")\n",
    "\n",
    "\n",
    "weights = {\n",
    "    \"w1\" : tf.Variable(tf.random_normal([input_features_num, hidden_layer_1_num]), \"w1\"),\n",
    "    \"w2\" : tf.Variable(tf.random_normal([hidden_layer_1_num, output_classes]), \"w2\")\n",
    "}\n",
    "biases = {\n",
    "    \"b1\" : tf.Variable(tf.random_normal([hidden_layer_1_num]), \"b1\"),\n",
    "    \"b2\" : tf.Variable(tf.random_normal([output_classes]), \"b2\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 三、 定义模型（网络结构）\n",
    "def mlp(x, weights, biases):\n",
    "    layer_1 = tf.matmul(x, weights[\"w1\"])\n",
    "    layer_1 = tf.add(layer_1, biases[\"b1\"])\n",
    "    layer_1 = tf.nn.relu(layer_1, name=\"relu\")\n",
    "    output = tf.matmul(layer_1, weights[\"w2\"])\n",
    "    output = tf.add(output, biases[\"b2\"])\n",
    "    return output\n",
    "pred_model = mlp(x, weights, biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 四、 定义（loss + optimizer + metric）\n",
    "loss_all = tf.nn.softmax_cross_entropy_with_logits_v2(logits=pred_model, labels=y, name=\"cross_entropy\")\n",
    "loss = tf.reduce_mean(loss_all)\n",
    "learning_rate = 0.01\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "# TD: metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.0 epoch: average loss = 14.0633\n",
      "No.1 epoch: average loss = 7.4847\n",
      "No.2 epoch: average loss = 3.6388\n",
      "No.3 epoch: average loss = 3.4996\n",
      "No.4 epoch: average loss = 2.4258\n",
      "No.5 epoch: average loss = 0.5741\n",
      "No.6 epoch: average loss = 0.1887\n",
      "No.7 epoch: average loss = 0.4168\n",
      "No.8 epoch: average loss = 0.6432\n",
      "No.9 epoch: average loss = 0.2020\n",
      "No.10 epoch: average loss = 0.0261\n",
      "No.11 epoch: average loss = 0.0097\n",
      "No.12 epoch: average loss = 0.0225\n",
      "No.13 epoch: average loss = 0.0458\n",
      "No.14 epoch: average loss = 0.0465\n",
      "No.15 epoch: average loss = 0.0254\n",
      "No.16 epoch: average loss = 0.0104\n",
      "No.17 epoch: average loss = 0.0041\n",
      "No.18 epoch: average loss = 0.0018\n",
      "No.19 epoch: average loss = 0.0009\n",
      "No.20 epoch: average loss = 0.0005\n",
      "No.21 epoch: average loss = 0.0003\n",
      "No.22 epoch: average loss = 0.0002\n",
      "No.23 epoch: average loss = 0.0002\n",
      "No.24 epoch: average loss = 0.0001\n",
      "No.25 epoch: average loss = 0.0001\n",
      "No.26 epoch: average loss = 0.0001\n",
      "No.27 epoch: average loss = 0.0001\n",
      "No.28 epoch: average loss = 0.0001\n",
      "No.29 epoch: average loss = 0.0001\n"
     ]
    }
   ],
   "source": [
    "#  五、 执行训练模型\n",
    "training_epochs = 30\n",
    "batch_size = 2\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(training_epochs):\n",
    "        total_batch_num = math.ceil(train_data_num/batch_size)\n",
    "        total_loss = 0\n",
    "        xy_iter = xy_iterator(train_features, train_labels)\n",
    "        for _ in range(total_batch_num):\n",
    "            xs, ys = xy_iter.next_batch(batch_size)\n",
    "            l, _ = sess.run([loss, optimizer], feed_dict={x:xs, y:ys})\n",
    "            total_loss += l\n",
    "        print(\"No.{0} epoch: average loss = {1:.4f}\".format(i, total_loss/total_batch_num))\n",
    "    \n",
    "    # 六、 预测 + 评估     \n",
    "    w,b = sess.run([weights, biases])\n",
    "    pred_y = sess.run(pred_model, feed_dict={x:[[1,1], [0, 1], [1, 0], [0, 0]]}) # 此处得到的是模型预测后的分值score\n",
    "    pred_yy = sess.run(tf.nn.softmax(pred_y)) #  经过softmax之后的值，才是各个类别中可能的概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.5718718,  -7.4700108],\n",
       "       [-14.71326  ,  -5.921864 ],\n",
       "       [-12.542423 ,  -1.3477553],\n",
       "       [  3.0018692,  -6.0426116]], dtype=float32)"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9988163e-01, 1.1833383e-04],\n",
       "       [1.5201260e-04, 9.9984801e-01],\n",
       "       [1.3747116e-05, 9.9998629e-01],\n",
       "       [9.9988198e-01, 1.1802674e-04]], dtype=float32)"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
